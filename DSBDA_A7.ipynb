{"cells":[{"cell_type":"markdown","source":["#TEOCD413 Dhairya Chhabra"],"metadata":{"id":"PPBaDcGhImYm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOqLHDjrIBzB"},"outputs":[],"source":["data = \"There were also many a night where Elise would sit with her son as he slept, meticulously piecing back together the tears that threatened the blanket entirely, wishing there was a way she could also mend her son. The room would be completely quiet save for the sound of Elise’s song. It was something she had done since she was his age. Inadvertently yet intentionally she would let the air slip through her lips, creating a tune just for him that would live for that moment, replaced the next time by one equally beautiful and equally unique.\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KFoIWh0HHain","outputId":"30647cf5-5224-46f5-8d53-fffce5b4e26b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting nltk\n","  File was already downloaded /content/nltk-3.7-py3-none-any.whl\n","Collecting regex>=2021.8.3\n","  File was already downloaded /content/regex-2022.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n","Collecting tqdm\n","  File was already downloaded /content/tqdm-4.63.0-py2.py3-none-any.whl\n","Collecting joblib\n","  File was already downloaded /content/joblib-1.1.0-py2.py3-none-any.whl\n","Collecting click\n","  File was already downloaded /content/click-8.0.4-py3-none-any.whl\n","Collecting importlib-metadata\n","  File was already downloaded /content/importlib_metadata-4.11.3-py3-none-any.whl\n","Collecting typing-extensions>=3.6.4\n","  File was already downloaded /content/typing_extensions-4.1.1-py3-none-any.whl\n","Collecting zipp>=0.5\n","  File was already downloaded /content/zipp-3.7.0-py3-none-any.whl\n","Successfully downloaded nltk regex click importlib-metadata typing-extensions zipp joblib tqdm\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package tagsets to /root/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["!pip download nltk\n","import nltk\n","nltk.download('stopwords')\n","from nltk.stem import PorterStemmer\n","word_stemmer = PorterStemmer()\n","from nltk.corpus import stopwords\n","stop_words = set(stopwords.words('english'))\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","vectorizer = TfidfVectorizer()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTtcJyB0Hr7Z","outputId":"c4d99636-87b6-449c-c150-60f05ea9de87"},"outputs":[{"name":"stdout","output_type":"stream","text":["['There', 'were', 'also', 'many', 'a', 'night', 'where', 'Elise', 'would', 'sit', 'with', 'her', 'son', 'as', 'he', 'slept', ',', 'meticulously', 'piecing', 'back', 'together', 'the', 'tears', 'that', 'threatened', 'the', 'blanket', 'entirely', ',', 'wishing', 'there', 'was', 'a', 'way', 'she', 'could', 'also', 'mend', 'her', 'son', '.', 'The', 'room', 'would', 'be', 'completely', 'quiet', 'save', 'for', 'the', 'sound', 'of', 'Elise', '’', 's', 'song', '.', 'It', 'was', 'something', 'she', 'had', 'done', 'since', 'she', 'was', 'his', 'age', '.', 'Inadvertently', 'yet', 'intentionally', 'she', 'would', 'let', 'the', 'air', 'slip', 'through', 'her', 'lips', ',', 'creating', 'a', 'tune', 'just', 'for', 'him', 'that', 'would', 'live', 'for', 'that', 'moment', ',', 'replaced', 'the', 'next', 'time', 'by', 'one', 'equally', 'beautiful', 'and', 'equally', 'unique', '.']\n"]}],"source":["from nltk.tokenize import word_tokenize\n","tokened_sen = word_tokenize(data)\n","print(word_tokenize(data))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21MUGBlgImnp","outputId":"2d481d33-0ae8-4b03-8728-17dbfd82d329"},"outputs":[{"data":{"text/plain":["[('There', 'EX'),\n"," ('were', 'VBD'),\n"," ('also', 'RB'),\n"," ('many', 'JJ'),\n"," ('a', 'DT'),\n"," ('night', 'NN'),\n"," ('where', 'WRB'),\n"," ('Elise', 'NNP'),\n"," ('would', 'MD'),\n"," ('sit', 'VB'),\n"," ('with', 'IN'),\n"," ('her', 'PRP$'),\n"," ('son', 'NN'),\n"," ('as', 'IN'),\n"," ('he', 'PRP'),\n"," ('slept', 'VBD'),\n"," (',', ','),\n"," ('meticulously', 'RB'),\n"," ('piecing', 'VBG'),\n"," ('back', 'RP'),\n"," ('together', 'RB'),\n"," ('the', 'DT'),\n"," ('tears', 'NNS'),\n"," ('that', 'WDT'),\n"," ('threatened', 'VBD'),\n"," ('the', 'DT'),\n"," ('blanket', 'NN'),\n"," ('entirely', 'RB'),\n"," (',', ','),\n"," ('wishing', 'VBG'),\n"," ('there', 'EX'),\n"," ('was', 'VBD'),\n"," ('a', 'DT'),\n"," ('way', 'NN'),\n"," ('she', 'PRP'),\n"," ('could', 'MD'),\n"," ('also', 'RB'),\n"," ('mend', 'VB'),\n"," ('her', 'PRP$'),\n"," ('son', 'NN'),\n"," ('.', '.'),\n"," ('The', 'DT'),\n"," ('room', 'NN'),\n"," ('would', 'MD'),\n"," ('be', 'VB'),\n"," ('completely', 'RB'),\n"," ('quiet', 'JJ'),\n"," ('save', 'NN'),\n"," ('for', 'IN'),\n"," ('the', 'DT'),\n"," ('sound', 'NN'),\n"," ('of', 'IN'),\n"," ('Elise', 'NNP'),\n"," ('’', 'NNP'),\n"," ('s', 'NN'),\n"," ('song', 'NN'),\n"," ('.', '.'),\n"," ('It', 'PRP'),\n"," ('was', 'VBD'),\n"," ('something', 'NN'),\n"," ('she', 'PRP'),\n"," ('had', 'VBD'),\n"," ('done', 'VBN'),\n"," ('since', 'IN'),\n"," ('she', 'PRP'),\n"," ('was', 'VBD'),\n"," ('his', 'PRP$'),\n"," ('age', 'NN'),\n"," ('.', '.'),\n"," ('Inadvertently', 'RB'),\n"," ('yet', 'RB'),\n"," ('intentionally', 'RB'),\n"," ('she', 'PRP'),\n"," ('would', 'MD'),\n"," ('let', 'VB'),\n"," ('the', 'DT'),\n"," ('air', 'NN'),\n"," ('slip', 'NN'),\n"," ('through', 'IN'),\n"," ('her', 'PRP$'),\n"," ('lips', 'NNS'),\n"," (',', ','),\n"," ('creating', 'VBG'),\n"," ('a', 'DT'),\n"," ('tune', 'NN'),\n"," ('just', 'RB'),\n"," ('for', 'IN'),\n"," ('him', 'PRP'),\n"," ('that', 'WDT'),\n"," ('would', 'MD'),\n"," ('live', 'VB'),\n"," ('for', 'IN'),\n"," ('that', 'DT'),\n"," ('moment', 'NN'),\n"," (',', ','),\n"," ('replaced', 'VBD'),\n"," ('the', 'DT'),\n"," ('next', 'JJ'),\n"," ('time', 'NN'),\n"," ('by', 'IN'),\n"," ('one', 'CD'),\n"," ('equally', 'RB'),\n"," ('beautiful', 'JJ'),\n"," ('and', 'CC'),\n"," ('equally', 'RB'),\n"," ('unique', 'JJ'),\n"," ('.', '.')]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["nltk.pos_tag(tokened_sen)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPaFFV7iJvCG","outputId":"29122047-acef-47c0-9773-941a054874df"},"outputs":[{"name":"stdout","output_type":"stream","text":["['There', 'also', 'many', 'night', 'Elise', 'would', 'sit', 'son', 'slept', ',', 'meticulously', 'piecing', 'back', 'together', 'tears', 'threatened', 'blanket', 'entirely', ',', 'wishing', 'way', 'could', 'also', 'mend', 'son', '.', 'The', 'room', 'would', 'completely', 'quiet', 'save', 'sound', 'Elise', '’', 'song', '.', 'It', 'something', 'done', 'since', 'age', '.', 'Inadvertently', 'yet', 'intentionally', 'would', 'let', 'air', 'slip', 'lips', ',', 'creating', 'tune', 'would', 'live', 'moment', ',', 'replaced', 'next', 'time', 'one', 'equally', 'beautiful', 'equally', 'unique', '.']\n"]}],"source":["Filtered_sen = [w for w in tokened_sen if w not in stop_words]\n","print(Filtered_sen)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfx5u7RcK6Ba","outputId":"3b92e43c-0710-4473-f20f-52e1724abdc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["There---->there\n","also---->also\n","many---->mani\n","night---->night\n","Elise---->elis\n","would---->would\n","sit---->sit\n","son---->son\n","slept---->slept\n",",---->,\n","meticulously---->meticul\n","piecing---->piec\n","back---->back\n","together---->togeth\n","tears---->tear\n","threatened---->threaten\n","blanket---->blanket\n","entirely---->entir\n",",---->,\n","wishing---->wish\n","way---->way\n","could---->could\n","also---->also\n","mend---->mend\n","son---->son\n",".---->.\n","The---->the\n","room---->room\n","would---->would\n","completely---->complet\n","quiet---->quiet\n","save---->save\n","sound---->sound\n","Elise---->elis\n","’---->’\n","song---->song\n",".---->.\n","It---->It\n","something---->someth\n","done---->done\n","since---->sinc\n","age---->age\n",".---->.\n","Inadvertently---->inadvert\n","yet---->yet\n","intentionally---->intent\n","would---->would\n","let---->let\n","air---->air\n","slip---->slip\n","lips---->lip\n",",---->,\n","creating---->creat\n","tune---->tune\n","would---->would\n","live---->live\n","moment---->moment\n",",---->,\n","replaced---->replac\n","next---->next\n","time---->time\n","one---->one\n","equally---->equal\n","beautiful---->beauti\n","equally---->equal\n","unique---->uniqu\n",".---->.\n"]}],"source":["for w in Filtered_sen:\n","  print(w + \"---->\"+word_stemmer.stem(w))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yiwpScbyLwIo","outputId":"821edd0d-2b70-4052-bcd3-eea1a0b3c0c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["There---->There\n","also---->also\n","many---->many\n","night---->night\n","Elise---->Elise\n","would---->would\n","sit---->sit\n","son---->son\n","slept---->slept\n",",---->,\n","meticulously---->meticulously\n","piecing---->piecing\n","back---->back\n","together---->together\n","tears---->tear\n","threatened---->threatened\n","blanket---->blanket\n","entirely---->entirely\n",",---->,\n","wishing---->wishing\n","way---->way\n","could---->could\n","also---->also\n","mend---->mend\n","son---->son\n",".---->.\n","The---->The\n","room---->room\n","would---->would\n","completely---->completely\n","quiet---->quiet\n","save---->save\n","sound---->sound\n","Elise---->Elise\n","’---->’\n","song---->song\n",".---->.\n","It---->It\n","something---->something\n","done---->done\n","since---->since\n","age---->age\n",".---->.\n","Inadvertently---->Inadvertently\n","yet---->yet\n","intentionally---->intentionally\n","would---->would\n","let---->let\n","air---->air\n","slip---->slip\n","lips---->lip\n",",---->,\n","creating---->creating\n","tune---->tune\n","would---->would\n","live---->live\n","moment---->moment\n",",---->,\n","replaced---->replaced\n","next---->next\n","time---->time\n","one---->one\n","equally---->equally\n","beautiful---->beautiful\n","equally---->equally\n","unique---->unique\n",".---->.\n"]}],"source":["for w in Filtered_sen:\n","  print(w + \"---->\"+lemmatizer.lemmatize(w))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L7VKVsTlMFwa","outputId":"ceb79b98-740e-4fb8-97a9-77424ba8a25d"},"outputs":[{"name":"stdout","output_type":"stream","text":["['there', 'were', 'also', 'many', 'night', 'where', 'elise', 'would', 'sit', 'with', 'her', 'son', 'as', 'he', 'slept', 'meticulously', 'piecing', 'back', 'together', 'the', 'tears', 'that', 'threatened', 'the', 'blanket', 'entirely', 'wishing', 'there', 'was', 'way', 'she', 'could', 'also', 'mend', 'her', 'son', 'the', 'room', 'would', 'be', 'completely', 'quiet', 'save', 'for', 'the', 'sound', 'of', 'elise', 'song', 'it', 'was', 'something', 'she', 'had', 'done', 'since', 'she', 'was', 'his', 'age', 'inadvertently', 'yet', 'intentionally', 'she', 'would', 'let', 'the', 'air', 'slip', 'through', 'her', 'lips', 'creating', 'tune', 'just', 'for', 'him', 'that', 'would', 'live', 'for', 'that', 'moment', 'replaced', 'the', 'next', 'time', 'by', 'one', 'equally', 'beautiful', 'and', 'equally', 'unique']\n"]}],"source":["analyze = vectorizer.build_analyzer()\n","X = vectorizer.fit_transform(data.split('.'))\n","print(analyze(data))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V3LgK-AtNPPx","outputId":"cb8b39ea-c496-4772-a711-8d06e4eb1d7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","idf values:\n","age : 2.09861228866811\n","air : 2.09861228866811\n","also : 2.09861228866811\n","and : 2.09861228866811\n","as : 2.09861228866811\n","back : 2.09861228866811\n","be : 2.09861228866811\n","beautiful : 2.09861228866811\n","blanket : 2.09861228866811\n","by : 2.09861228866811\n","completely : 2.09861228866811\n","could : 2.09861228866811\n","creating : 2.09861228866811\n","done : 2.09861228866811\n","elise : 1.6931471805599454\n","entirely : 2.09861228866811\n","equally : 2.09861228866811\n","for : 1.6931471805599454\n","had : 2.09861228866811\n","he : 2.09861228866811\n","her : 1.6931471805599454\n","him : 2.09861228866811\n","his : 2.09861228866811\n","inadvertently : 2.09861228866811\n","intentionally : 2.09861228866811\n","it : 2.09861228866811\n","just : 2.09861228866811\n","let : 2.09861228866811\n","lips : 2.09861228866811\n","live : 2.09861228866811\n","many : 2.09861228866811\n","mend : 2.09861228866811\n","meticulously : 2.09861228866811\n","moment : 2.09861228866811\n","next : 2.09861228866811\n","night : 2.09861228866811\n","of : 2.09861228866811\n","one : 2.09861228866811\n","piecing : 2.09861228866811\n","quiet : 2.09861228866811\n","replaced : 2.09861228866811\n","room : 2.09861228866811\n","save : 2.09861228866811\n","she : 1.4054651081081644\n","since : 2.09861228866811\n","sit : 2.09861228866811\n","slept : 2.09861228866811\n","slip : 2.09861228866811\n","something : 2.09861228866811\n","son : 2.09861228866811\n","song : 2.09861228866811\n","sound : 2.09861228866811\n","tears : 2.09861228866811\n","that : 1.6931471805599454\n","the : 1.4054651081081644\n","there : 2.09861228866811\n","threatened : 2.09861228866811\n","through : 2.09861228866811\n","time : 2.09861228866811\n","together : 2.09861228866811\n","tune : 2.09861228866811\n","unique : 2.09861228866811\n","was : 1.6931471805599454\n","way : 2.09861228866811\n","were : 2.09861228866811\n","where : 2.09861228866811\n","wishing : 2.09861228866811\n","with : 2.09861228866811\n","would : 1.4054651081081644\n","yet : 2.09861228866811\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["print('\\nidf values:')\n","for ele1, ele2 in zip(vectorizer.get_feature_names(), vectorizer.idf_):\n","    print(ele1, ':', ele2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TD8Ue-DCOe9P","outputId":"735b85ee-f0dc-46a0-9e63-ad0c05e35c82"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Word indexes:\n","{'there': 55, 'were': 64, 'also': 2, 'many': 30, 'night': 35, 'where': 65, 'elise': 14, 'would': 68, 'sit': 45, 'with': 67, 'her': 20, 'son': 49, 'as': 4, 'he': 19, 'slept': 46, 'meticulously': 32, 'piecing': 38, 'back': 5, 'together': 59, 'the': 54, 'tears': 52, 'that': 53, 'threatened': 56, 'blanket': 8, 'entirely': 15, 'wishing': 66, 'was': 62, 'way': 63, 'she': 43, 'could': 11, 'mend': 31, 'room': 41, 'be': 6, 'completely': 10, 'quiet': 39, 'save': 42, 'for': 17, 'sound': 51, 'of': 36, 'song': 50, 'it': 25, 'something': 48, 'had': 18, 'done': 13, 'since': 44, 'his': 22, 'age': 0, 'inadvertently': 23, 'yet': 69, 'intentionally': 24, 'let': 27, 'air': 1, 'slip': 47, 'through': 57, 'lips': 28, 'creating': 12, 'tune': 60, 'just': 26, 'him': 21, 'live': 29, 'moment': 33, 'replaced': 40, 'next': 34, 'time': 58, 'by': 9, 'one': 37, 'equally': 16, 'beautiful': 7, 'and': 3, 'unique': 61}\n","\n","tf-idf value:\n","  (0, 31)\t0.15762698682993861\n","  (0, 11)\t0.15762698682993861\n","  (0, 43)\t0.105564630152006\n","  (0, 63)\t0.15762698682993861\n","  (0, 62)\t0.12717246047417838\n","  (0, 66)\t0.15762698682993861\n","  (0, 15)\t0.15762698682993861\n","  (0, 8)\t0.15762698682993861\n","  (0, 56)\t0.15762698682993861\n","  (0, 53)\t0.12717246047417838\n","  (0, 52)\t0.15762698682993861\n","  (0, 54)\t0.211129260304012\n","  (0, 59)\t0.15762698682993861\n","  (0, 5)\t0.15762698682993861\n","  (0, 38)\t0.15762698682993861\n","  (0, 32)\t0.15762698682993861\n","  (0, 46)\t0.15762698682993861\n","  (0, 19)\t0.15762698682993861\n","  (0, 4)\t0.15762698682993861\n","  (0, 49)\t0.31525397365987723\n","  (0, 20)\t0.25434492094835676\n","  (0, 67)\t0.15762698682993861\n","  (0, 45)\t0.15762698682993861\n","  (0, 68)\t0.105564630152006\n","  (0, 14)\t0.12717246047417838\n","  :\t:\n","  (3, 37)\t0.1669105620486018\n","  (3, 9)\t0.1669105620486018\n","  (3, 58)\t0.1669105620486018\n","  (3, 34)\t0.1669105620486018\n","  (3, 40)\t0.1669105620486018\n","  (3, 33)\t0.1669105620486018\n","  (3, 29)\t0.1669105620486018\n","  (3, 21)\t0.1669105620486018\n","  (3, 26)\t0.1669105620486018\n","  (3, 60)\t0.1669105620486018\n","  (3, 12)\t0.1669105620486018\n","  (3, 28)\t0.1669105620486018\n","  (3, 57)\t0.1669105620486018\n","  (3, 47)\t0.1669105620486018\n","  (3, 1)\t0.1669105620486018\n","  (3, 27)\t0.1669105620486018\n","  (3, 24)\t0.1669105620486018\n","  (3, 69)\t0.1669105620486018\n","  (3, 23)\t0.1669105620486018\n","  (3, 17)\t0.26932478101290586\n","  (3, 43)\t0.11178194867185966\n","  (3, 53)\t0.26932478101290586\n","  (3, 54)\t0.22356389734371931\n","  (3, 20)\t0.13466239050645293\n","  (3, 68)\t0.22356389734371931\n","\n","tf-idf values in matrix form:\n","[[0.         0.         0.31525397 0.         0.15762699 0.15762699\n","  0.         0.         0.15762699 0.         0.         0.15762699\n","  0.         0.         0.12717246 0.15762699 0.         0.\n","  0.         0.15762699 0.25434492 0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.15762699 0.15762699 0.15762699 0.         0.         0.15762699\n","  0.         0.         0.15762699 0.         0.         0.\n","  0.         0.10556463 0.         0.15762699 0.15762699 0.\n","  0.         0.31525397 0.         0.         0.15762699 0.12717246\n","  0.21112926 0.31525397 0.15762699 0.         0.         0.15762699\n","  0.         0.         0.12717246 0.15762699 0.15762699 0.15762699\n","  0.15762699 0.15762699 0.10556463 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.29431629 0.         0.         0.         0.29431629 0.\n","  0.         0.         0.23745253 0.         0.         0.23745253\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.29431629 0.         0.         0.29431629 0.         0.29431629\n","  0.29431629 0.         0.         0.         0.         0.\n","  0.         0.         0.29431629 0.29431629 0.         0.\n","  0.3942141  0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.19710705 0.        ]\n"," [0.29620407 0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.29620407 0.         0.         0.         0.\n","  0.29620407 0.         0.         0.         0.29620407 0.\n","  0.         0.29620407 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.39674264 0.29620407 0.         0.         0.\n","  0.29620407 0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.47795116 0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.16691056 0.         0.16691056 0.         0.\n","  0.         0.16691056 0.         0.16691056 0.         0.\n","  0.16691056 0.         0.         0.         0.33382112 0.26932478\n","  0.         0.         0.13466239 0.16691056 0.         0.16691056\n","  0.16691056 0.         0.16691056 0.16691056 0.16691056 0.16691056\n","  0.         0.         0.         0.16691056 0.16691056 0.\n","  0.         0.16691056 0.         0.         0.16691056 0.\n","  0.         0.11178195 0.         0.         0.         0.16691056\n","  0.         0.         0.         0.         0.         0.26932478\n","  0.2235639  0.         0.         0.16691056 0.16691056 0.\n","  0.16691056 0.16691056 0.         0.         0.         0.\n","  0.         0.         0.2235639  0.16691056]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]]\n"]}],"source":["print('\\nWord indexes:')\n","print(vectorizer.vocabulary_)\n","  \n","# display tf-idf values\n","print('\\ntf-idf value:')\n","print(X)\n","  \n","# in matrix form\n","print('\\ntf-idf values in matrix form:')\n","print(X.toarray())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sc-mLjvjPS8C"},"outputs":[],"source":[""]}],"metadata":{"colab":{"name":"TECOD413_A7.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}